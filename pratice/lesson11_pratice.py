# ---------------------------------------------------------------------------------------- #
# https://chtseng.wordpress.com/2017/09/12/%E5%88%9D%E6%8E%A2%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/
# CNN的架構
# 傳統的DNN（即Deep neural network，泛指一般的深度學習網路）最大問題在於它會忽略資料的形狀。
# 例如，輸入影像的資料時，該data通常包含了水平、垂直、color channel等三維資訊，但傳統DNN的輸入處理必須是平面的、也就是須一維的資料。
# 還記得我們之前舉例過用DNN來分類MNIST手寫數字集嗎？其影像資訊是水平28 pixels、垂直28 pixels、color channel=1，即(1, 28, 28)的形狀，
# 但輸入DNN時，所有dataset必須轉為一維，欄位數為784的dataset。
#
# 因此，若去除了這些形狀資訊，就代表失去了一些重要的空間資料，像不同影像但類似的空間可能有著相似的像素值，
# RGB不同的channel之間也可能具有某些關連性、而遠近不同的像素彼此也應具有不同的關聯性，而這些資訊只有在三維形狀中才能保留下來。
#
# 因此，Deep learning中的CNN較傳統的DNN多了Convolutional（卷積）及池化（Pooling） 兩層layer，用以維持形狀資訊並且避免參數大幅增加。
# 在加入此兩層後，我們所看到的架構就如下圖分別有兩層的卷積和池化層，以及一個全連結層（即傳統的DNN），
# 最後再使用Softmax activation function來輸出分類結果。
# ---------------------------------------------------------------------------------------- #
# 卷積 :
# 卷積的過程中，如果binary的黑白圖片中有一個形狀與該kernel所表示的形狀類似（即kernel中大於0的格子），就會產生激勵效果，
# 兩者相乘的乘積會變成更大或更小的數。如下圖所示，kernel由左至右由上而下滑動會得到9組圖形。
# 再經過ReLU函數處理，將小於0的值輸出為0，大於0則直接輸出，此結果即為所謂的feature map，
# 此feature map上的每一點皆可視為原圖形中該區域的特徵並傳遞給下一層，CNN的卷積層就是專注在取得圖形的這些局部特徵。
# 範例中kernel是逐步移動一格，因此我們稱其stride步長為一（這個值是定義CNN時的hyperparameter之一哦!），
# 如果我們把stride加大，那麼涵蓋的特徵會比較少，但速度較快，得出的feature map更小。
# 此外，在上例中，您會發現最後得到的feature map比起原圖要小，此種情況稱為valid padding，
# 如果我們希望輸出的是與原圖同等大小的圖形，那麼就需要在原圖周圍補上0（如下圖所示），此種於周圍補零的方式則稱為zero-padding。
# zero-padding除了可維持輸出圖形大小不變之外，也有抑制圖像邊緣的效果，因為一般情況下我們認為圖像的中間部分比起周圍更重要。
# 取圖像各區域的特徵值再與kernel各點的權重相乘計算最後得到feature map，此map會傳給下游的池化層。
# 所以在多個捲積層中，圖像透過kernel萃取後的特徵濃縮再傳遞給下一層，
# 因此愈上層的捲積層會對更小的特徵起反應，而kernel的weight值會在反向傳播時逐次依loss值用ReLU activate function進行梯度修正。
# ---------------------------------------------------------------------------------------- #
# Pooling layer :
# Pooling layer稱為池化層，它的功能很單純，就是將輸入的圖片尺寸縮小（大部份為縮小一半）以減少每張feature map維度並保留重要的特徵
# ------------------------------------------- #
# 好處有：
# 減少後續layer需要參數，加快系統運作的效率。
# 具有抗干擾的作用：圖像中某些像素在鄰近區域有微小偏移或差異時，對Pooling layer的輸出影響不大，結果仍是不變的。
# 減少過度擬合over-fitting的情況。
# ------------------------------------------- #
# 與卷積層相同，池化層會使用kernel來取出各區域的值並運算，但最後的輸出並不透過Activate function（卷積層使用的function是ReLU）。
# 另外，池化層用來縮小圖像尺寸的作法主要有三種：最大化（Max-Pooling）、平均化（Mean-Pooling）、隨機（Stochastic-Pooling）…等
# 不過最常用的Pooling kernel size是2×2，Stride為2，這個設定可縮小一半尺寸並減少75%運算量，
# 可以看出池化層減少了圖素的參數數量，卻保留了所有重要的特徵資訊，對於CNN的運作效率增進不少。
# ---------------------------------------------------------------------------------------- #
# Full connected layer
# Full connected layer指的就是一般的神經網路，您可以參考之前的Neural Networks系列的知識文件。
#
# 前面提到的卷積和池化層，其最主要的目的分別是提取特徵及減少圖像參數，然後將特徵資訊丟到Full connected layer來進行分類，
# 其神經元只與上一層kernel的像素連結，而且各連結的權重在同層中是相同且共享的，
# 然而Full connected layer的每個神經元與上層神經元之間彼此相連接，各個連結都有其獨立且相異的權重值，
# 這個現象造成Full connected layer會耗用相當多的運算資源。
# 例如有個圖像其尺寸是1000×1000，那麼在第一層就會有100萬個像素維度（1000×1000），
# 到了下一層隱藏層，將會double成一萬億個帶有不同權重的連結(即100萬的平方)，
# 因此Full connected layer的運算成本（Memory 、CPU或GPU）相較於卷積與池化相當昂貴，這是在設計網路架構時必須考慮的，
# ---------------------------------------------------------------------------------------- #
# 課程 :
# 透過卷積核 (Kernels) 滑動對圖像做訊息提取，並藉由步長 (Strides) 與填充 (Padding) 控制圖像的長寬。
# ---------------------------------------------------------------------------------------- #
# 卷積核:
# 又稱為 Filter、Kernel、feature detector (下圖黃色區塊) --> 神經元
# 卷積核大小(kernel_size)：自定義，常見大小如 3*3、5*5。 --> (3*3*1)*5 = 45個神經元 --> 大小*層數*張數
# 用途： Kernel 用來學習圖像的特徵，Kernel 的張數 (filters) 決定學習的參數量，
# Kernel 大小決定 Kernels 的特徵接受域 (Receptive field)，也就是看到特徵的大小。
# 起始值：一個 3*3的 Kernel，其中的值就是我們要訓練的權重，通常用常態分佈隨機產生，再經由訓練更新。
# 張數：控制張數主要就是控制學習的參數量，常見是16、32 或 64，如果使用16張 Kernels 就能達到很好的效果，
# 也就不需要浪費額外的參數去增加學習與計算量。
# 3*3的Kernel 對到圖像藉由各點相乘後，相加算出一個值，
# 再往下一步走(先往右走，再往下走)，直到走完整張的圖像。
# Kernel 大小影響 ：
# Kernel 大小與其 Receptive field 有關，Receptive field 直觀來說就是 Kernel 提取資訊的尺度，
# 現在普遍流行的方式是選用不同大小的 Kernel 對圖像做卷積後，再把輸出的 Feature maps 合併或平均。
# 常見的Kernel大小有 1*1, 3*3, 5*5, 7*7。
# 然而也有人提出，兩層 3*3 的Kernel 卷積與一層的 5*5 Kernel 卷積擁有相近的Receptive field，並且使用較少的參數量。
# ------------------------------------------- #
# 為什麼 Kernel 都是奇數的呢？
# 奇數Kernel有幾個先天上的優勢，
# 第一個原因是由於基數的卷積核有中心點，較容易對齊確認位置資訊，
# 再者是因為基數的卷積核能確保Padding的對稱性。
# ---------------------------------------------------------------------------------------- #
# CNN 的重點與優勢:
# 1. 權值共享
# 試想今天假如是一般的FC(Full connected layer)架構，我們輸入一張28*28*1的灰階照片(784個特徵)，
# 隱藏層使用100個神經元，那麼我們需要多少個參數？
# 答案是：
# 100*784 (weights)+100 (bias)= 78500個參數，單單一層隱藏層參數就瞬間爆量，然而，如果我們使用CNN層的話情況就有所不同了。
# 在一般的圖像內有許多的特徵是相同的，如特定的輪廓或線條，因此可以使用相同幾個神經元組成的卷積核去學這個特徵，
# 透過滑動窗口對整張圖片進行卷積，進而達到節省參數的效果。
# 2. 保留空間資訊
# CNN 還能保留圖像的位置資訊，圖片中的像素 (Pixels) 與其鄰近的像素會有一定的關聯度，
# 使用 FC 層來訓練圖像資訊的話，要先通過一個展開 (Flatten)的步驟，把高維的資訊拉成一條一維向量，造成大量空間資訊的流失。
# ---------------------------------------------------------------------------------------- #
# ---------------------------------------------------------------------------------------- #
# ---------------------------------------------------------------------------------------- #
# 作業內容：運用Keras搭建簡單的Dense Layer與 Convolution2D Layer，使用相同Neurons數量，計算總參數量相差多少。
# 再params上可以看出CNN與FC層的參數使用量差異極大
from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import Input, Dense
from keras.models import Model
# 輸入照片尺寸==28*28*1
# 都用一層，288個神經元
# 建造一個一層的CNN層
classifier=Sequential()
# Kernel size 3*3，用32張，輸入大小28*28*1
classifier.add(Convolution2D(32,3,3,input_shape=(28,28,1)))
# 看看model結構
print(classifier.summary())
# Total params=(3*3*1+1)*32=320
# 建造一個一層的FC層
classifier=Sequential()
# 輸入為28*28*1攤平==784
inputs = Input(shape=(784,))
# CNN中用了(3*3*1)*32個神經元，我們這邊也用相同神經元數量
x=Dense(288)(inputs)
model = Model(inputs=inputs, outputs=x)
# 看看model結構
print(model.summary())
# Total params=784*288+288=226080











































